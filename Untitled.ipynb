{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a08926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dados_treino = pd.read_csv(\"treino.csv\")\n",
    "dados_teste = pd.read_csv(\"teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c17c9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Após polêmica, Marine Le Pen diz que abomina n...</td>\n",
       "      <td>A candidata da direita nacionalista à Presidên...</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Macron e Le Pen vão ao 2º turno na França, em ...</td>\n",
       "      <td>O centrista independente Emmanuel Macron e a d...</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apesar de larga vitória nas legislativas, Macr...</td>\n",
       "      <td>As eleições legislativas deste domingo (19) na...</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/06/189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Governo antecipa balanço, e Alckmin anuncia qu...</td>\n",
       "      <td>O número de ocorrências de homicídios dolosos ...</td>\n",
       "      <td>2015-07-24</td>\n",
       "      <td>cotidiano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/cotidiano/2015/07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Após queda em maio, a atividade econômica sobe...</td>\n",
       "      <td>A economia cresceu 0,25% no segundo trimestre,...</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Após polêmica, Marine Le Pen diz que abomina n...   \n",
       "1  Macron e Le Pen vão ao 2º turno na França, em ...   \n",
       "2  Apesar de larga vitória nas legislativas, Macr...   \n",
       "3  Governo antecipa balanço, e Alckmin anuncia qu...   \n",
       "4  Após queda em maio, a atividade econômica sobe...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  A candidata da direita nacionalista à Presidên...  2017-04-28      mundo   \n",
       "1  O centrista independente Emmanuel Macron e a d...  2017-04-23      mundo   \n",
       "2  As eleições legislativas deste domingo (19) na...  2017-06-19      mundo   \n",
       "3  O número de ocorrências de homicídios dolosos ...  2015-07-24  cotidiano   \n",
       "4  A economia cresceu 0,25% no segundo trimestre,...  2017-08-17    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "1         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "2         NaN  http://www1.folha.uol.com.br/mundo/2017/06/189...  \n",
       "3         NaN  http://www1.folha.uol.com.br/cotidiano/2015/07...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/08/1...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8dd34dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\bielf\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30680dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbee2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Rio de Janeiro é uma cidade maravilhosa\"\n",
    "doc = nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9623a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7221b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_para_tratamento = (titulos.lower() for titulos in dados_treino[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959ff202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_textos(doc):\n",
    "    tokens_validos = []\n",
    "    for token in doc:\n",
    "        e_valido = not token.is_stop and token.is_alpha\n",
    "        if e_valido:\n",
    "            tokens_validos.append(token.text)\n",
    "    if len(tokens_validos) > 2:\n",
    "        return \" \".join(tokens_validos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a001797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rio Janeiro cidade maravilhosa'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trata_textos(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17eb1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_tratados = [trata_textos(doc) for doc in nlp.pipe(textos_para_tratamento,\n",
    "                                                            batch_size = 1000,\n",
    "                                                            n_process = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "677ae5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polêmica marine le pen abomina negacionistas h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macron le pen turno frança revés siglas tradic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apesar larga vitória legislativas macron terá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>governo antecipa balanço alckmin anuncia queda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queda maio atividade econômica sobe junho bc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>mural há anos aeroporto recebido moradores gua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>notícias schumacher boas ferrari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>olho bilhões governo conceder áreas petróleo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>moro deu lula papel coitadinho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>velocidade aprovação reformas excedido expecta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  titulo\n",
       "0      polêmica marine le pen abomina negacionistas h...\n",
       "1      macron le pen turno frança revés siglas tradic...\n",
       "2      apesar larga vitória legislativas macron terá ...\n",
       "3      governo antecipa balanço alckmin anuncia queda...\n",
       "4           queda maio atividade econômica sobe junho bc\n",
       "...                                                  ...\n",
       "89995  mural há anos aeroporto recebido moradores gua...\n",
       "89996                   notícias schumacher boas ferrari\n",
       "89997       olho bilhões governo conceder áreas petróleo\n",
       "89998                     moro deu lula papel coitadinho\n",
       "89999  velocidade aprovação reformas excedido expecta...\n",
       "\n",
       "[90000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulos_tratados = pd.DataFrame({\"titulo\": textos_tratados})\n",
    "titulos_tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b192bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\bielf\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Requirement already satisfied: pyfume in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Requirement already satisfied: simpful in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.11.0)\n",
      "Requirement already satisfied: fst-pso in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in c:\\users\\bielf\\anaconda3\\lib\\site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fbd3915",
   "metadata": {},
   "outputs": [],
   "source": [
    " from gensim.models import Word2Vec\n",
    "\n",
    "w2v_modelo = Word2Vec(sg = 0,\n",
    "                     window = 2,\n",
    "                     vector_size = 300,\n",
    "                     min_count = 5,\n",
    "                     alpha = 0.03,\n",
    "                     min_alpha = 0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3bb30a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x193cf5dea70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac98e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "84466\n"
     ]
    }
   ],
   "source": [
    "print(len(titulos_tratados))\n",
    "\n",
    "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\n",
    "\n",
    "print(len(titulos_tratados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb74d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_lista_tokens =  [titulo.split(\" \") for titulo in titulos_tratados.titulo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b673c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_modelo.build_vocab(lista_lista_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb50f991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x193cf5dea70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13afd1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "&(asctime)s : - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2023-11-14T10:58:03.010313', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n",
      "&(asctime)s : - collecting all words and their counts\n",
      "&(asctime)s : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #1000, processed 6497 words, keeping 3764 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #2000, processed 12858 words, keeping 5857 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #3000, processed 19195 words, keeping 7543 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #4000, processed 25567 words, keeping 8965 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #6000, processed 38343 words, keeping 11352 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #7000, processed 44726 words, keeping 12398 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #8000, processed 51114 words, keeping 13330 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #9000, processed 57427 words, keeping 14172 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #11000, processed 70243 words, keeping 15705 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #12000, processed 76603 words, keeping 16426 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #13000, processed 82977 words, keeping 17050 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #14000, processed 89323 words, keeping 17697 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #16000, processed 102158 words, keeping 18897 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #17000, processed 108509 words, keeping 19452 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #18000, processed 114908 words, keeping 19995 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #19000, processed 121307 words, keeping 20546 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #21000, processed 134072 words, keeping 21574 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #22000, processed 140467 words, keeping 22060 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #23000, processed 146804 words, keeping 22515 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #24000, processed 153181 words, keeping 23012 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #26000, processed 166009 words, keeping 23944 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #27000, processed 172439 words, keeping 24377 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #28000, processed 178814 words, keeping 24757 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #29000, processed 185138 words, keeping 25140 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #31000, processed 197960 words, keeping 25873 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #32000, processed 204300 words, keeping 26229 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #33000, processed 210663 words, keeping 26606 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #34000, processed 216981 words, keeping 26982 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #36000, processed 229750 words, keeping 27686 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #37000, processed 236169 words, keeping 28033 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #38000, processed 242574 words, keeping 28388 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #39000, processed 248948 words, keeping 28732 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #41000, processed 261710 words, keeping 29382 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #42000, processed 268076 words, keeping 29681 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #43000, processed 274474 words, keeping 29991 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #44000, processed 280891 words, keeping 30308 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #46000, processed 293687 words, keeping 30871 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #47000, processed 300151 words, keeping 31151 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #48000, processed 306512 words, keeping 31444 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #49000, processed 312907 words, keeping 31704 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #51000, processed 325681 words, keeping 32242 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #52000, processed 332169 words, keeping 32521 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #53000, processed 338629 words, keeping 32774 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #54000, processed 345085 words, keeping 33021 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #56000, processed 357811 words, keeping 33543 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #57000, processed 364257 words, keeping 33806 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #58000, processed 370652 words, keeping 34056 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #59000, processed 377107 words, keeping 34261 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #61000, processed 390016 words, keeping 34751 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #62000, processed 396383 words, keeping 34978 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #63000, processed 402722 words, keeping 35193 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #64000, processed 409142 words, keeping 35406 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #66000, processed 421961 words, keeping 35850 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #67000, processed 428335 words, keeping 36071 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #68000, processed 434849 words, keeping 36268 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #69000, processed 441213 words, keeping 36486 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #71000, processed 453997 words, keeping 36961 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #72000, processed 460368 words, keeping 37172 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #73000, processed 466745 words, keeping 37391 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #74000, processed 473163 words, keeping 37619 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #76000, processed 486054 words, keeping 38022 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #77000, processed 492516 words, keeping 38215 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #78000, processed 498939 words, keeping 38406 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #79000, processed 505249 words, keeping 38606 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #81000, processed 518077 words, keeping 38993 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #82000, processed 524485 words, keeping 39203 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #83000, processed 530917 words, keeping 39397 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #84000, processed 537292 words, keeping 39587 word types\n",
      "&(asctime)s : - collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
      "&(asctime)s : - Creating a fresh vocabulary\n",
      "&(asctime)s : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.56% of original 39693, drops 26769)', 'datetime': '2023-11-14T10:58:03.350120', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "&(asctime)s : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.67% of original 540242, drops 45019)', 'datetime': '2023-11-14T10:58:03.351119', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "&(asctime)s : - deleting the raw counts dictionary of 39693 items\n",
      "&(asctime)s : - sample=0.001 downsamples 8 most-common words\n",
      "&(asctime)s : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2023-11-14T10:58:03.433080', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "&(asctime)s : - estimated required memory for 12924 words and 300 dimensions: 37479600 bytes\n",
      "&(asctime)s : - resetting layer weights\n",
      "&(asctime)s : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-14T10:58:03.574991', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format = \"&(asctime)s : - %(message)s\", level = logging.INFO)\n",
    "\n",
    "w2v_modelo = Word2Vec(sg = 0,\n",
    "                     window = 2,\n",
    "                     vector_size = 300,\n",
    "                     min_count = 5,\n",
    "                     alpha = 0.03,\n",
    "                     min_alpha = 0.007)\n",
    "\n",
    "w2v_modelo.build_vocab(lista_lista_tokens,progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd757248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84466"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83fc697d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "&(asctime)s : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2023-11-14T10:58:03.602003', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "&(asctime)s : - EPOCH 0: training on 540242 raw words (486170 effective words) took 0.5s, 884577 effective words/s\n",
      "&(asctime)s : - EPOCH 1: training on 540242 raw words (486188 effective words) took 0.5s, 908766 effective words/s\n",
      "&(asctime)s : - EPOCH 2: training on 540242 raw words (486170 effective words) took 0.5s, 893072 effective words/s\n",
      "&(asctime)s : - EPOCH 3: training on 540242 raw words (486137 effective words) took 0.5s, 900314 effective words/s\n",
      "&(asctime)s : - EPOCH 4: training on 540242 raw words (486152 effective words) took 0.6s, 862514 effective words/s\n",
      "&(asctime)s : - EPOCH 5: training on 540242 raw words (486121 effective words) took 0.5s, 908110 effective words/s\n",
      "&(asctime)s : - EPOCH 6: training on 540242 raw words (486059 effective words) took 0.6s, 872899 effective words/s\n",
      "&(asctime)s : - EPOCH 7: training on 540242 raw words (486203 effective words) took 0.6s, 858863 effective words/s\n",
      "&(asctime)s : - EPOCH 8: training on 540242 raw words (486160 effective words) took 0.5s, 916115 effective words/s\n",
      "&(asctime)s : - EPOCH 9: training on 540242 raw words (486306 effective words) took 0.5s, 906840 effective words/s\n",
      "&(asctime)s : - EPOCH 10: training on 540242 raw words (486050 effective words) took 0.5s, 896833 effective words/s\n",
      "&(asctime)s : - EPOCH 11: training on 540242 raw words (486194 effective words) took 0.5s, 894550 effective words/s\n",
      "&(asctime)s : - EPOCH 12: training on 540242 raw words (486118 effective words) took 0.5s, 911241 effective words/s\n",
      "&(asctime)s : - EPOCH 13: training on 540242 raw words (486144 effective words) took 0.6s, 856093 effective words/s\n",
      "&(asctime)s : - EPOCH 14: training on 540242 raw words (486143 effective words) took 0.6s, 840496 effective words/s\n",
      "&(asctime)s : - EPOCH 15: training on 540242 raw words (486113 effective words) took 0.5s, 917152 effective words/s\n",
      "&(asctime)s : - EPOCH 16: training on 540242 raw words (486095 effective words) took 0.5s, 910375 effective words/s\n",
      "&(asctime)s : - EPOCH 17: training on 540242 raw words (486156 effective words) took 0.5s, 934697 effective words/s\n",
      "&(asctime)s : - EPOCH 18: training on 540242 raw words (486242 effective words) took 0.5s, 911563 effective words/s\n",
      "&(asctime)s : - EPOCH 19: training on 540242 raw words (485995 effective words) took 0.5s, 929593 effective words/s\n",
      "&(asctime)s : - EPOCH 20: training on 540242 raw words (486033 effective words) took 0.5s, 948091 effective words/s\n",
      "&(asctime)s : - EPOCH 21: training on 540242 raw words (486058 effective words) took 0.5s, 959532 effective words/s\n",
      "&(asctime)s : - EPOCH 22: training on 540242 raw words (486255 effective words) took 0.6s, 882130 effective words/s\n",
      "&(asctime)s : - EPOCH 23: training on 540242 raw words (486075 effective words) took 0.5s, 939337 effective words/s\n",
      "&(asctime)s : - EPOCH 24: training on 540242 raw words (486112 effective words) took 0.5s, 925171 effective words/s\n",
      "&(asctime)s : - EPOCH 25: training on 540242 raw words (486014 effective words) took 0.5s, 929550 effective words/s\n",
      "&(asctime)s : - EPOCH 26: training on 540242 raw words (486330 effective words) took 0.5s, 952301 effective words/s\n",
      "&(asctime)s : - EPOCH 27: training on 540242 raw words (486180 effective words) took 0.5s, 953348 effective words/s\n",
      "&(asctime)s : - EPOCH 28: training on 540242 raw words (486117 effective words) took 0.5s, 942688 effective words/s\n",
      "&(asctime)s : - EPOCH 29: training on 540242 raw words (486254 effective words) took 0.6s, 881242 effective words/s\n",
      "&(asctime)s : - Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14584344 effective words) took 16.5s, 882891 effective words/s', 'datetime': '2023-11-14T10:58:20.121673', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14584344, 16207260)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.train(lista_lista_tokens,\n",
    "                 total_examples=w2v_modelo.corpus_count,\n",
    "                epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fb2f921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trator', 0.5568035840988159),\n",
       " ('poste', 0.44873669743537903),\n",
       " ('caminhão', 0.4360007345676422),\n",
       " ('anhanguera', 0.4347541630268097),\n",
       " ('motociclista', 0.41956576704978943),\n",
       " ('caminhões', 0.4032784402370453),\n",
       " ('veículo', 0.3989909589290619),\n",
       " ('carros', 0.39240092039108276),\n",
       " ('motorista', 0.38509538769721985),\n",
       " ('carreta', 0.383258193731308)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar(\"carro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a3e514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "&(asctime)s : - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2023-11-14T10:58:20.200117', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n",
      "&(asctime)s : - collecting all words and their counts\n",
      "&(asctime)s : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #1000, processed 6497 words, keeping 3764 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #2000, processed 12858 words, keeping 5857 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #3000, processed 19195 words, keeping 7543 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #4000, processed 25567 words, keeping 8965 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #6000, processed 38343 words, keeping 11352 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #7000, processed 44726 words, keeping 12398 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #8000, processed 51114 words, keeping 13330 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #9000, processed 57427 words, keeping 14172 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #11000, processed 70243 words, keeping 15705 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #12000, processed 76603 words, keeping 16426 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #13000, processed 82977 words, keeping 17050 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #14000, processed 89323 words, keeping 17697 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #16000, processed 102158 words, keeping 18897 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #17000, processed 108509 words, keeping 19452 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #18000, processed 114908 words, keeping 19995 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #19000, processed 121307 words, keeping 20546 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #21000, processed 134072 words, keeping 21574 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #22000, processed 140467 words, keeping 22060 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #23000, processed 146804 words, keeping 22515 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #24000, processed 153181 words, keeping 23012 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #26000, processed 166009 words, keeping 23944 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #27000, processed 172439 words, keeping 24377 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #28000, processed 178814 words, keeping 24757 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #29000, processed 185138 words, keeping 25140 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #31000, processed 197960 words, keeping 25873 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #32000, processed 204300 words, keeping 26229 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #33000, processed 210663 words, keeping 26606 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #34000, processed 216981 words, keeping 26982 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #36000, processed 229750 words, keeping 27686 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #37000, processed 236169 words, keeping 28033 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #38000, processed 242574 words, keeping 28388 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #39000, processed 248948 words, keeping 28732 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #41000, processed 261710 words, keeping 29382 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #42000, processed 268076 words, keeping 29681 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #43000, processed 274474 words, keeping 29991 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #44000, processed 280891 words, keeping 30308 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #46000, processed 293687 words, keeping 30871 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #47000, processed 300151 words, keeping 31151 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #48000, processed 306512 words, keeping 31444 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #49000, processed 312907 words, keeping 31704 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #51000, processed 325681 words, keeping 32242 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #52000, processed 332169 words, keeping 32521 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #53000, processed 338629 words, keeping 32774 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #54000, processed 345085 words, keeping 33021 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #56000, processed 357811 words, keeping 33543 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #57000, processed 364257 words, keeping 33806 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #58000, processed 370652 words, keeping 34056 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #59000, processed 377107 words, keeping 34261 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #61000, processed 390016 words, keeping 34751 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #62000, processed 396383 words, keeping 34978 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #63000, processed 402722 words, keeping 35193 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #64000, processed 409142 words, keeping 35406 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #66000, processed 421961 words, keeping 35850 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #67000, processed 428335 words, keeping 36071 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #68000, processed 434849 words, keeping 36268 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #69000, processed 441213 words, keeping 36486 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #71000, processed 453997 words, keeping 36961 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #72000, processed 460368 words, keeping 37172 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #73000, processed 466745 words, keeping 37391 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #74000, processed 473163 words, keeping 37619 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #76000, processed 486054 words, keeping 38022 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #77000, processed 492516 words, keeping 38215 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #78000, processed 498939 words, keeping 38406 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #79000, processed 505249 words, keeping 38606 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #81000, processed 518077 words, keeping 38993 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #82000, processed 524485 words, keeping 39203 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #83000, processed 530917 words, keeping 39397 word types\n",
      "&(asctime)s : - PROGRESS: at sentence #84000, processed 537292 words, keeping 39587 word types\n",
      "&(asctime)s : - collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
      "&(asctime)s : - Creating a fresh vocabulary\n",
      "&(asctime)s : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.56% of original 39693, drops 26769)', 'datetime': '2023-11-14T10:58:20.563908', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "&(asctime)s : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.67% of original 540242, drops 45019)', 'datetime': '2023-11-14T10:58:20.563908', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "&(asctime)s : - deleting the raw counts dictionary of 39693 items\n",
      "&(asctime)s : - sample=0.001 downsamples 8 most-common words\n",
      "&(asctime)s : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2023-11-14T10:58:20.645027', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "&(asctime)s : - estimated required memory for 12924 words and 300 dimensions: 37479600 bytes\n",
      "&(asctime)s : - resetting layer weights\n",
      "&(asctime)s : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-14T10:58:20.780949', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'}\n",
      "&(asctime)s : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-11-14T10:58:20.781948', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "&(asctime)s : - EPOCH 0 - PROGRESS: at 72.19% examples, 346053 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 0: training on 540242 raw words (486059 effective words) took 1.4s, 352269 effective words/s\n",
      "&(asctime)s : - EPOCH 1 - PROGRESS: at 74.06% examples, 341158 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 1: training on 540242 raw words (486124 effective words) took 1.4s, 352095 effective words/s\n",
      "&(asctime)s : - EPOCH 2 - PROGRESS: at 70.35% examples, 341826 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 2: training on 540242 raw words (486280 effective words) took 1.4s, 344408 effective words/s\n",
      "&(asctime)s : - EPOCH 3 - PROGRESS: at 68.53% examples, 331516 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 3: training on 540242 raw words (486140 effective words) took 1.4s, 342392 effective words/s\n",
      "&(asctime)s : - EPOCH 4 - PROGRESS: at 74.04% examples, 348698 words/s, in_qsize 4, out_qsize 1\n",
      "&(asctime)s : - EPOCH 4: training on 540242 raw words (486223 effective words) took 1.3s, 364835 effective words/s\n",
      "&(asctime)s : - EPOCH 5 - PROGRESS: at 74.06% examples, 343768 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 5: training on 540242 raw words (486101 effective words) took 1.4s, 356851 effective words/s\n",
      "&(asctime)s : - EPOCH 6 - PROGRESS: at 70.35% examples, 337442 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 6: training on 540242 raw words (486097 effective words) took 1.4s, 344503 effective words/s\n",
      "&(asctime)s : - EPOCH 7 - PROGRESS: at 72.19% examples, 349495 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 7: training on 540242 raw words (486102 effective words) took 1.4s, 351316 effective words/s\n",
      "&(asctime)s : - EPOCH 8 - PROGRESS: at 74.06% examples, 352202 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 8: training on 540242 raw words (486196 effective words) took 1.4s, 357778 effective words/s\n",
      "&(asctime)s : - EPOCH 9 - PROGRESS: at 68.53% examples, 332362 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 9: training on 540242 raw words (486148 effective words) took 1.4s, 347462 effective words/s\n",
      "&(asctime)s : - EPOCH 10 - PROGRESS: at 70.35% examples, 333520 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 10: training on 540242 raw words (486161 effective words) took 1.4s, 346451 effective words/s\n",
      "&(asctime)s : - EPOCH 11 - PROGRESS: at 74.06% examples, 354987 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 11: training on 540242 raw words (486302 effective words) took 1.4s, 355189 effective words/s\n",
      "&(asctime)s : - EPOCH 12 - PROGRESS: at 74.06% examples, 348049 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 12: training on 540242 raw words (486095 effective words) took 1.4s, 359567 effective words/s\n",
      "&(asctime)s : - EPOCH 13 - PROGRESS: at 72.19% examples, 340438 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 13: training on 540242 raw words (486045 effective words) took 1.4s, 349083 effective words/s\n",
      "&(asctime)s : - EPOCH 14 - PROGRESS: at 74.06% examples, 346352 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 14: training on 540242 raw words (486072 effective words) took 1.4s, 356205 effective words/s\n",
      "&(asctime)s : - EPOCH 15 - PROGRESS: at 74.06% examples, 353115 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 15: training on 540242 raw words (486020 effective words) took 1.3s, 362125 effective words/s\n",
      "&(asctime)s : - EPOCH 16 - PROGRESS: at 74.06% examples, 348671 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 16: training on 540242 raw words (486169 effective words) took 1.4s, 356861 effective words/s\n",
      "&(asctime)s : - EPOCH 17 - PROGRESS: at 74.04% examples, 349709 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 17: training on 540242 raw words (486082 effective words) took 1.4s, 356443 effective words/s\n",
      "&(asctime)s : - EPOCH 18 - PROGRESS: at 74.04% examples, 342056 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 18: training on 540242 raw words (486206 effective words) took 1.3s, 363546 effective words/s\n",
      "&(asctime)s : - EPOCH 19 - PROGRESS: at 79.60% examples, 369168 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 19: training on 540242 raw words (486094 effective words) took 1.3s, 373931 effective words/s\n",
      "&(asctime)s : - EPOCH 20 - PROGRESS: at 74.06% examples, 355868 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 20: training on 540242 raw words (486249 effective words) took 1.3s, 374415 effective words/s\n",
      "&(asctime)s : - EPOCH 21 - PROGRESS: at 75.91% examples, 366095 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 21: training on 540242 raw words (486130 effective words) took 1.3s, 371051 effective words/s\n",
      "&(asctime)s : - EPOCH 22 - PROGRESS: at 74.06% examples, 339234 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 22: training on 540242 raw words (486080 effective words) took 1.4s, 356790 effective words/s\n",
      "&(asctime)s : - EPOCH 23 - PROGRESS: at 74.06% examples, 350883 words/s, in_qsize 4, out_qsize 1\n",
      "&(asctime)s : - EPOCH 23: training on 540242 raw words (486146 effective words) took 1.3s, 370412 effective words/s\n",
      "&(asctime)s : - EPOCH 24 - PROGRESS: at 74.06% examples, 355367 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 24: training on 540242 raw words (486156 effective words) took 1.3s, 367687 effective words/s\n",
      "&(asctime)s : - EPOCH 25 - PROGRESS: at 75.91% examples, 368610 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 25: training on 540242 raw words (486199 effective words) took 1.3s, 374512 effective words/s\n",
      "&(asctime)s : - EPOCH 26 - PROGRESS: at 74.06% examples, 355259 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 26: training on 540242 raw words (486263 effective words) took 1.3s, 369815 effective words/s\n",
      "&(asctime)s : - EPOCH 27 - PROGRESS: at 68.53% examples, 326891 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 27: training on 540242 raw words (486091 effective words) took 1.5s, 327030 effective words/s\n",
      "&(asctime)s : - EPOCH 28 - PROGRESS: at 68.53% examples, 327176 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 28: training on 540242 raw words (486285 effective words) took 1.5s, 334282 effective words/s\n",
      "&(asctime)s : - EPOCH 29 - PROGRESS: at 72.19% examples, 346674 words/s, in_qsize 5, out_qsize 0\n",
      "&(asctime)s : - EPOCH 29: training on 540242 raw words (486152 effective words) took 1.5s, 327590 effective words/s\n",
      "&(asctime)s : - Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14584467 effective words) took 41.5s, 351647 effective words/s', 'datetime': '2023-11-14T10:59:02.257830', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14584467, 16207260)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Treinamento do modelo Skip-Gram\n",
    "w2v_modelo_sg = Word2Vec(sg = 1,\n",
    "                     window = 5,\n",
    "                     vector_size = 300,\n",
    "                     min_count = 5,\n",
    "                     alpha = 0.03,\n",
    "                     min_alpha = 0.007)\n",
    "\n",
    "w2v_modelo_sg.build_vocab(lista_lista_tokens,progress_per=1000)\n",
    "w2v_modelo_sg.train(lista_lista_tokens,\n",
    "                 total_examples=w2v_modelo_sg.corpus_count,\n",
    "                epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "511529cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barça', 0.4874124825000763),\n",
       " ('cavani', 0.46490946412086487),\n",
       " ('suárez', 0.45646852254867554),\n",
       " ('messi', 0.4527904689311981),\n",
       " ('psg', 0.4278981685638428),\n",
       " ('benzema', 0.4227941036224365),\n",
       " ('celta', 0.40962454676628113),\n",
       " ('dedada', 0.4095214009284973),\n",
       " ('villarreal', 0.4021708071231842),\n",
       " ('camp', 0.3987097442150116)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"neymar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46a28345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('messi', 0.49554121494293213),\n",
       " ('benzema', 0.4439714252948761),\n",
       " ('cristiane', 0.4386359453201294),\n",
       " ('psg', 0.4349348843097687),\n",
       " ('barça', 0.4346559941768646),\n",
       " ('valdivia', 0.43324288725852966),\n",
       " ('suárez', 0.412927508354187),\n",
       " ('mordida', 0.41186028718948364),\n",
       " ('ronaldo', 0.411583811044693),\n",
       " ('fred', 0.41106271743774414)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar(\"neymar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8160d172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "&(asctime)s : - storing 12924x300 projection weights into modelo_cbow.txt\n",
      "&(asctime)s : - storing 12924x300 projection weights into modelo_skipgram.txt\n"
     ]
    }
   ],
   "source": [
    "w2v_modelo.wv.save_word2vec_format(\"modelo_cbow.txt\",\n",
    "                                  binary = False)\n",
    "w2v_modelo_sg.wv.save_word2vec_format(\"modelo_skipgram.txt\",\n",
    "                                  binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7adb0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\", disable = [\"paser,ner\",\"tagger\",\"textcat\"])\n",
    "\n",
    "def tokenizador(texto):\n",
    "    \n",
    "    doc = nlp(texto)\n",
    "    tokens_validos = []\n",
    "    for token in doc:\n",
    "        e_valido = not token.is_stop and token.is_alpha\n",
    "        if e_valido:\n",
    "            tokens_validos.append(token.text.lower())\n",
    "            \n",
    "    return tokens_validos\n",
    "tokens = tokenizador(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a59a0513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "&(asctime)s : - loading projection weights from modelo_cbow.txt\n",
      "&(asctime)s : - KeyedVectors lifecycle event {'msg': 'loaded (12924, 300) matrix of type float32 from modelo_cbow.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-11-14T10:59:16.216973', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'}\n",
      "&(asctime)s : - loading projection weights from modelo_skipgram.txt\n",
      "&(asctime)s : - KeyedVectors lifecycle event {'msg': 'loaded (12924, 300) matrix of type float32 from modelo_skipgram.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-11-14T10:59:20.449130', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[ 0.82281831  0.06578609  1.72163936 -1.47442374  0.95933092  1.30971995\n",
      "  -3.17180413  0.50781728  0.26268046 -1.18491122  0.51470327  0.14534891\n",
      "  -1.17114021  0.49812633  0.54357263 -2.14302841 -0.36421683 -0.4247142\n",
      "   0.64938045  0.87775405 -0.1321882  -0.94368169  0.30457675 -0.42685981\n",
      "   0.36518952 -1.20521208  0.6550624  -0.06647955 -0.28584187  0.77789596\n",
      "  -1.46940552 -1.32872955 -0.11195271  2.33269835  1.06839517 -0.66005678\n",
      "  -2.44503927 -1.74646415  0.55869782 -0.44895555 -0.53319846  1.54230047\n",
      "   0.24562095 -0.2947053  -1.97813445 -2.57872699  1.88771886 -1.3340553\n",
      "   1.7351207  -0.33257326 -0.61099644 -1.57800359  0.86319357 -0.73724084\n",
      "  -0.93352227  1.39657522  0.59622282 -1.32115211  0.92856466  0.22798309\n",
      "  -0.65944448 -1.53630483  1.6264572  -1.2831412   1.07152845 -0.59626346\n",
      "   1.46276464 -0.10697895  0.24676916 -1.29809782  0.91367812  2.18233034\n",
      "   0.09042094 -0.72699174  0.61282896  1.22481928  0.27294788  0.32449384\n",
      "  -1.51306945  1.14770435 -1.51094604  2.6116485  -0.9050159   1.75100698\n",
      "   0.67240089 -1.24839234 -1.2517676   0.0158031   0.0170617   0.24859051\n",
      "  -0.15615967 -0.09975854  0.18913294 -1.83851117  1.19069059  1.28509176\n",
      "   1.81635503  0.38205811  0.73761734  0.33008783  0.13954167  0.15751117\n",
      "   0.38252804  1.16493681 -1.13463166  2.12425598 -1.68533386  1.68381307\n",
      "  -1.10501534  0.38048742  0.03005721 -0.08769333  0.44115341 -0.96691242\n",
      "   1.68045889 -0.32537253  0.72980902  0.30399242 -2.49250186 -0.72623482\n",
      "   2.26564282  0.12362598  1.74721     1.57115799  0.57069968  3.77326953\n",
      "  -1.9493351  -2.85590851 -0.25149995  3.68812114  2.19396254  0.08219974\n",
      "   1.4060801  -1.45357114  0.36382343 -1.95581463 -1.43316722  1.64177287\n",
      "   0.44853955 -1.24562383 -1.36635841 -1.40432913  2.04191622  1.59556696\n",
      "   2.12902111 -1.15779526 -0.99771189 -0.19310799  0.02977785  1.84833574\n",
      "  -0.54741383 -3.25311828 -1.18302158 -1.52303548  0.32631329  0.04021893\n",
      "   0.59398559 -1.08195589 -0.35268801  3.66409916  0.99220154  2.29556543\n",
      "   1.35039404 -0.32180288  0.96817861 -0.14669802  0.41992043  2.12722708\n",
      "   1.60407925  1.44259242  0.73198482  1.00851278 -0.1855443  -0.98231672\n",
      "   1.20435053  0.58908755  1.94974883  0.81540312  2.36359824 -0.81518053\n",
      "   1.17898699 -1.16142052  0.83575979 -0.59015265  0.29242254 -0.54333502\n",
      "  -0.37307963  1.41237592  0.82702461  0.27151209  0.53810814  1.74405557\n",
      "  -0.31865537 -0.44702238 -2.46094736  0.22213175  1.97048949 -0.47990897\n",
      "   1.4462131  -1.5791579  -1.46534496  2.14677335 -1.36019437  0.67577592\n",
      "   1.08372764 -0.83642355  1.83162034  1.93527693  1.57472435 -0.87716374\n",
      "  -1.0326652  -0.36822701 -1.32162811 -0.64173418 -1.47223553 -0.5624429\n",
      "   1.92412889  0.1816802   0.0460347  -2.64813212 -0.56409907  0.82836204\n",
      "   0.19236213 -0.72248209 -2.80452928  2.37039782  1.3976309  -1.42499018\n",
      "  -2.30871972 -1.19086133 -2.92334688 -1.03785277  0.85983713 -1.34133013\n",
      "  -0.88253547 -1.98014244 -0.10431139 -1.57507378  0.3239921   0.11901575\n",
      "   1.51873858 -0.6111551   1.79766747 -3.54931116  2.40237702 -0.18209513\n",
      "  -1.92781243  0.55462533 -0.75629699 -1.79466331  0.98653983  1.25072813\n",
      "   3.67566061 -2.13539621 -0.72218165 -1.70414542  1.2863313  -0.17327631\n",
      "  -3.85099946 -2.73727211 -0.18690631 -0.92500615  0.41056295  0.8650496\n",
      "  -0.24432031 -0.82064788  0.08651862 -0.38341133 -3.24493888 -3.6526885\n",
      "  -2.15833812  2.18120405 -0.36019471 -0.07317879  0.4766164  -1.66930044\n",
      "   1.49204013  1.29706007 -0.06317785 -1.49149188 -1.64297393 -0.04062521\n",
      "  -2.02970754  1.09659508  3.92434844 -0.11934372 -1.32196045 -2.6539517\n",
      "  -0.25541218 -0.22119746  0.16629207  0.7852394   1.19760582  0.60753855\n",
      "   0.02089629 -0.53657713 -0.68558292  1.71618063  0.96853215  0.53303283]]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "w2v_modelo_cbow = KeyedVectors.load_word2vec_format(\"modelo_cbow.txt\")\n",
    "w2v_modelo_skipgram = KeyedVectors.load_word2vec_format(\"modelo_skipgram.txt\")\n",
    "\n",
    "def combinacao_de_vetores_por_soma(palavras,modelo):\n",
    "    vetor_resultante = np.zeros((1,300))\n",
    "    \n",
    "    for pn in palavras:\n",
    "        try:\n",
    "            vetor_resultante += modelo.get_vector(pn)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return vetor_resultante\n",
    "\n",
    "vetor_texto = combinacao_de_vetores_por_soma(tokens,w2v_modelo_cbow)\n",
    "print(len(vetor_texto))\n",
    "print(vetor_texto)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "650c0b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 300)\n",
      "(20513, 300)\n"
     ]
    }
   ],
   "source": [
    "def matriz_vetores(textos,modelo):\n",
    "    x = len(textos)\n",
    "    y = 300\n",
    "    matriz = np.zeros((x,y))\n",
    "    \n",
    "    for i in range(x):\n",
    "        palavras = tokenizador(textos.iloc[i])\n",
    "        matriz[i] = combinacao_de_vetores_por_soma(palavras,modelo)\n",
    "    return matriz\n",
    "\n",
    "matriz_vetores_treino_cbow = matriz_vetores(dados_treino.title,w2v_modelo_cbow)\n",
    "matriz_vetores_teste_cbow = matriz_vetores(dados_teste.title,w2v_modelo_cbow)\n",
    "print(matriz_vetores_treino_cbow.shape)\n",
    "print(matriz_vetores_teste_cbow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5667ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     colunas       0.80      0.70      0.75      6103\n",
      "   cotidiano       0.64      0.80      0.71      1698\n",
      "     esporte       0.93      0.86      0.89      4663\n",
      "   ilustrada       0.13      0.84      0.22       131\n",
      "     mercado       0.83      0.78      0.81      5867\n",
      "       mundo       0.74      0.84      0.79      2051\n",
      "\n",
      "    accuracy                           0.78     20513\n",
      "   macro avg       0.68      0.80      0.69     20513\n",
      "weighted avg       0.82      0.78      0.80     20513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classificador(modelo,x_treino,y_treino,x_teste,y_teste):\n",
    "    \n",
    "    RL = LogisticRegression(max_iter=800)\n",
    "    RL.fit(x_treino,y_treino)\n",
    "    categorias = RL.predict(x_teste)\n",
    "    resultados = classification_report(y_teste,categorias)\n",
    "    print(resultados)\n",
    "    \n",
    "    return RL\n",
    "    \n",
    "RL_cbow = classificador(w2v_modelo_cbow,matriz_vetores_treino_cbow,\n",
    "                       dados_treino.category,matriz_vetores_teste_cbow,\n",
    "                       dados_teste.category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2d0b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_vetores_treino_sg = matriz_vetores(dados_treino.title, w2v_modelo_skipgram)\n",
    "matriz_vetores_teste_sg = matriz_vetores(dados_teste.title, w2v_modelo_skipgram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8926d956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     colunas       0.80      0.70      0.75      6103\n",
      "   cotidiano       0.64      0.80      0.71      1698\n",
      "     esporte       0.93      0.86      0.89      4663\n",
      "   ilustrada       0.13      0.84      0.22       131\n",
      "     mercado       0.83      0.78      0.81      5867\n",
      "       mundo       0.74      0.84      0.79      2051\n",
      "\n",
      "    accuracy                           0.78     20513\n",
      "   macro avg       0.68      0.80      0.69     20513\n",
      "weighted avg       0.82      0.78      0.80     20513\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     colunas       0.80      0.72      0.76      6103\n",
      "   cotidiano       0.64      0.80      0.71      1698\n",
      "     esporte       0.93      0.87      0.90      4663\n",
      "   ilustrada       0.14      0.89      0.25       131\n",
      "     mercado       0.84      0.79      0.82      5867\n",
      "       mundo       0.75      0.84      0.79      2051\n",
      "\n",
      "    accuracy                           0.79     20513\n",
      "   macro avg       0.69      0.82      0.70     20513\n",
      "weighted avg       0.82      0.79      0.80     20513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RL_cbow = classificador(w2v_modelo_cbow, matriz_vetores_treino_cbow,\n",
    "                        dados_treino.category, matriz_vetores_teste_cbow,\n",
    "                        dados_teste.category)\n",
    "\n",
    "RL_skipgram = classificador(w2v_modelo_skipgram, matriz_vetores_treino_sg,\n",
    "                           dados_treino.category, matriz_vetores_teste_sg,\n",
    "                           dados_teste.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac099228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
